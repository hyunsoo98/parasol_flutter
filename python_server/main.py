#!/usr/bin/env python3
"""
FastAPI ì„œë²„ - íŒŒí‚¨ìŠ¨ë³‘ ì§„ë‹¨ Eye Tracking API
"""
from fastapi import FastAPI, File, UploadFile, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import os
import sys
import tempfile
import uuid
import time
import math
import json
from typing import Dict, Any, Optional, Tuple, List
import cv2
import numpy as np
import pandas as pd
import mediapipe as mp
from mediapipe.solutions import face_mesh as mp_face_mesh
from mediapipe.solutions.face_mesh_connections import (
    FACEMESH_LEFT_IRIS,
    FACEMESH_RIGHT_IRIS,
)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="Parkinson's Disease Eye Tracking API",
    description="MediaPipe ê¸°ë°˜ ëˆˆ ì¶”ì  ë¶„ì„ API",
    version="1.0.0"
)

# CORS ì„¤ì • (Flutter ì•±ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ì‹¤ì œ ìš´ì˜ì—ì„œëŠ” êµ¬ì²´ì ì¸ ë„ë©”ì¸ ì§€ì •
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# MediaPipe ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (eye_model.pyì—ì„œ ë³µì‚¬)
def _uniq_indices(connections: List[Tuple[int, int]]) -> List[int]:
    s = set()
    for a, b in connections:
        s.add(a); s.add(b)
    return sorted(list(s))

LEFT_IRIS_IDXS  = _uniq_indices(FACEMESH_LEFT_IRIS)
RIGHT_IRIS_IDXS = _uniq_indices(FACEMESH_RIGHT_IRIS)

# ëˆˆ ëª¨ì„œë¦¬/ìœ—/ì•„ë«ëˆˆêº¼í’€ ëŒ€í‘œ ëœë“œë§ˆí¬
L_CORNER_OUT, L_CORNER_IN = 33, 133
L_LID_TOP,   L_LID_BOT    = 159, 145
R_CORNER_OUT, R_CORNER_IN = 362, 263
R_LID_TOP,   R_LID_BOT    = 386, 374

def _px(landmark, w, h) -> Tuple[float, float]:
    return landmark.x * w, landmark.y * h

def _iris_center(landmarks, idxs, w, h) -> Tuple[float, float]:
    xs, ys = [], []
    for i in idxs:
        x, y = _px(landmarks[i], w, h)
        xs.append(x); ys.append(y)
    if not xs:
        return np.nan, np.nan
    return float(np.mean(xs)), float(np.mean(ys))

def _eye_metrics(landmarks, w, h, is_left=True) -> Dict[str, float]:
    if is_left:
        c_out, c_in = L_CORNER_OUT, L_CORNER_IN
        lid_top, lid_bot = L_LID_TOP, L_LID_BOT
        iris_idxs = LEFT_IRIS_IDXS
    else:
        c_out, c_in = R_CORNER_OUT, R_CORNER_IN
        lid_top, lid_bot = R_LID_TOP, R_LID_BOT
        iris_idxs = RIGHT_IRIS_IDXS

    # ê°€ë¡œí­(ì •ê·œí™” ê¸°ì¤€)
    x_out, y_out = _px(landmarks[c_out], w, h)
    x_in,  y_in  = _px(landmarks[c_in],  w, h)
    eye_width = max(1e-6, math.hypot(x_out - x_in, y_out - y_in))

    # ì„¸ë¡œ ê°œíë„
    x_t, y_t = _px(landmarks[lid_top], w, h)
    x_b, y_b = _px(landmarks[lid_bot], w, h)
    eye_open = math.hypot(x_t - x_b, y_t - y_b) / eye_width

    # í™ì±„ ì¤‘ì‹¬ê³¼ ëˆˆ ì¤‘ì•™/ë†’ì´ ê¸°ì¤€ ì •ê·œí™” ìœ„ì¹˜
    ix, iy = _iris_center(landmarks, iris_idxs, w, h)
    cx, cy = (x_out + x_in) / 2.0, (y_out + y_in) / 2.0
    eye_height = max(1e-6, math.hypot(x_t - x_b, y_t - y_b))
    v_offset_norm = (iy - cy) / eye_height

    return {
        "eye_width": eye_width,
        "eye_open": eye_open,
        "iris_cx": ix,
        "iris_cy": iy,
        "eye_cx": cx,
        "eye_cy": cy,
        "v_offset_norm": v_offset_norm,
    }

def count_blinks(openness_series: List[float], thresh: float = 0.18, min_frames: int = 2) -> int:
    closed = False
    hold = 0
    count = 0
    for v in openness_series:
        if np.isnan(v):
            if closed and hold >= min_frames:
                count += 1
            closed, hold = False, 0
            continue

        if v < thresh:
            if closed:
                hold += 1
            else:
                closed = True
                hold = 1
        else:
            if closed and hold >= min_frames:
                count += 1
            closed, hold = False, 0

    if closed and hold >= min_frames:
        count += 1
    return count

@app.get("/")
async def root():
    return {"message": "Parkinson's Eye Tracking API Server"}

@app.get("/health")
async def health_check():
    return {"status": "ok", "message": "ì„œë²„ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤"}

@app.post("/api/eye-tracking")
async def analyze_eye_tracking(
    file: UploadFile = File(..., description="mp4 ë¹„ë””ì˜¤ íŒŒì¼"),
    step: int = Query(1, description="í”„ë ˆì„ ìƒ˜í”Œë§ ê°„ê²©"),
    vpp_thresh: float = Query(0.06, description="PSP ì˜ì‹¬ íŒì •ìš© ìˆ˜ì§ ì„ê³„ê°’"),
    blink_thresh: float = Query(0.18, description="ëˆˆêº¼í’€ ë‹«í˜ íŒì • ì„ê³„ì¹˜"),
    max_frames: int = Query(12000, description="ìµœëŒ€ ì²˜ë¦¬ í”„ë ˆì„")
):
    """ëˆˆ ì¶”ì  ë¶„ì„ API - Flutter ì•±ì—ì„œ í˜¸ì¶œ"""
    
    # íŒŒì¼ íƒ€ì… ê²€ì¦
    if not file.content_type or not file.content_type.startswith('video/'):
        raise HTTPException(400, detail="ë¹„ë””ì˜¤ íŒŒì¼ë§Œ í—ˆìš©ë©ë‹ˆë‹¤")
    
    try:
        # ì—…ë¡œë“œëœ íŒŒì¼ ì½ê¸°
        content = await file.read()
        if not content:
            raise HTTPException(400, detail="ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤")
        
        # ì„ì‹œ íŒŒì¼ ìƒì„± ë° ë¹„ë””ì˜¤ ì²˜ë¦¬
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
            tmp_file.write(content)
            tmp_file.flush()
            
            # OpenCVë¡œ ë¹„ë””ì˜¤ ì—´ê¸°
            cap = cv2.VideoCapture(tmp_file.name)
            if not cap.isOpened():
                raise HTTPException(400, detail="ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            fps = cap.get(cv2.CAP_PROP_FPS) or 30.0
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) or 0)
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) or 0)
            
            # MediaPipe FaceMesh ì´ˆê¸°í™”
            fm = mp_face_mesh.FaceMesh(
                static_image_mode=False,
                max_num_faces=1,
                refine_landmarks=True,
                min_detection_confidence=0.5,
                min_tracking_confidence=0.5,
            )
            
            # í”„ë ˆì„ ì²˜ë¦¬
            rows = []
            fidx = 0
            kept = 0
            
            while kept < max_frames:
                ret, frame = cap.read()
                if not ret:
                    break
                    
                if fidx % step != 0:
                    fidx += 1
                    continue
                
                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                result = fm.process(rgb)
                t_sec = fidx / max(1e-6, fps)
                
                if result.multi_face_landmarks:
                    landmarks = result.multi_face_landmarks[0].landmark
                    
                    # ì¢Œ/ìš° ëˆˆ ë©”íŠ¸ë¦­ ê³„ì‚°
                    L = _eye_metrics(landmarks, width, height, is_left=True)
                    R = _eye_metrics(landmarks, width, height, is_left=False)
                    
                    # í‰ê·  ê°’ ê³„ì‚°
                    v_offset = np.nanmean([L["v_offset_norm"], R["v_offset_norm"]])
                    eye_open = np.nanmean([L["eye_open"], R["eye_open"]])
                    
                    rows.append({
                        "frame_idx": fidx,
                        "time_sec": t_sec,
                        "L_v_offset": L["v_offset_norm"],
                        "R_v_offset": R["v_offset_norm"],
                        "L_eye_open": L["eye_open"],
                        "R_eye_open": R["eye_open"],
                        "v_offset": v_offset,
                        "eye_open": eye_open,
                    })
                else:
                    # ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì€ í”„ë ˆì„
                    rows.append({
                        "frame_idx": fidx,
                        "time_sec": t_sec,
                        "L_v_offset": np.nan,
                        "R_v_offset": np.nan,
                        "L_eye_open": np.nan,
                        "R_eye_open": np.nan,
                        "v_offset": np.nan,
                        "eye_open": np.nan,
                    })
                
                kept += 1
                fidx += 1
            
            cap.release()
            fm.close()
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.unlink(tmp_file.name)
        
        if not rows:
            raise HTTPException(400, detail="ìœ íš¨í•œ í”„ë ˆì„ì„ ì²˜ë¦¬í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
        
        # ë°ì´í„° ë¶„ì„
        df = pd.DataFrame(rows)
        v_series = df["v_offset"].to_numpy(dtype=float)
        eye_open_series = df["eye_open"].to_numpy(dtype=float)
        
        # NaN ì œê±°
        v_valid = v_series[~np.isnan(v_series)]
        open_valid = eye_open_series[~np.isnan(eye_open_series)]
        
        # ìˆ˜ì§ ì›€ì§ì„ ë¶„ì„
        def robust_ptp(x: np.ndarray) -> float:
            if x.size == 0:
                return float("nan")
            lo, hi = np.percentile(x, [5, 95])
            return float(hi - lo)
        
        v_ptp = robust_ptp(v_valid)
        v_std = float(np.nanstd(v_valid)) if v_valid.size else float("nan")
        
        # ë¸”ë§í¬ ë¶„ì„
        blink_count = count_blinks(open_valid.tolist(), thresh=blink_thresh)
        dur_sec = float(df["time_sec"].max() - df["time_sec"].min()) if len(df) > 1 else 0.0
        blink_rate_per_min = (blink_count / dur_sec * 60.0) if dur_sec > 0 else 0.0
        
        # PSP ì˜ì‹¬ íŒì •
        psp_suspected = bool(v_ptp < vpp_thresh) if not math.isnan(v_ptp) else False
        
        # ê²°ê³¼ ë°˜í™˜
        return {
            "success": True,
            "analysis_result": {
                "frames_processed": len(df),
                "duration_sec": dur_sec,
                "vertical_movement": {
                    "peak_to_peak": v_ptp,
                    "std_deviation": v_std
                },
                "blink_analysis": {
                    "count": blink_count,
                    "rate_per_minute": blink_rate_per_min
                },
                "psp_screening": {
                    "suspected": psp_suspected,
                    "threshold_used": vpp_thresh,
                    "vertical_ptp_measured": v_ptp
                }
            },
            "raw_data": rows[:100] if len(rows) > 100 else rows  # ì²˜ìŒ 100í”„ë ˆì„ë§Œ ë°˜í™˜
        }
        
    except Exception as e:
        raise HTTPException(500, detail=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    print("ğŸš€ íŒŒí‚¨ìŠ¨ë³‘ ì§„ë‹¨ Eye Tracking API ì„œë²„ ì‹œì‘")
    print("ğŸ“Š MediaPipe ê¸°ë°˜ ëˆˆ ì¶”ì  ë¶„ì„")
    print("ğŸŒ ì„œë²„ ì£¼ì†Œ: http://localhost:8000")
    print("ğŸ“– API ë¬¸ì„œ: http://localhost:8000/docs")
    
    uvicorn.run(app, host="0.0.0.0", port=8000)